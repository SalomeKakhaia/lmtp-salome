---
title: "Using LMTP"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{try}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<style type="text/css">
.table {

    width: 50%;
    margin: 0 auto;  

}
</style>

__Authors__: [Nick Williams](https://nicholastwilliams.com) and [Ivan Diaz](https://idiaz.xyz)  
__Updated__: `r Sys.Date()` 

This document serves as an introductory guide to using the `lmtp` package. `lmtp` provides an estimation framework for the casual effects of longitudinal modified treatment policies of continuous valued exposures using ensemble machine learning. While primarily developed to estimate the effect of continuous exposures, `lmtp` naturally extends to allowing the estimation of traditional causal effects based on binary exposure in both point treatment and time-varying situations. 

While not possible to cover everything, this document should equip users of `lmtp` with enough knowledge to complete the majority of use cases. 

```{r}
library(lmtp)
```

## Functions & parameters

> The goal of this section is to introduce the main `lmtp` functions and develop a basic understanding of required and useful function parameters.

### The estimators

`lmtp` supplies 2 main estimators: 

- a targeted maximum likelihood (TML) estimator: `lmtp_tmle()`
- a sequentially doubly robust (SDR) estimator: `lmtp_sdr()`

Two auxillary estimators are also provided, however, the use of these estimators is recommended against in favors of the TML or SDR estimators: 

- a substitution estimator: `lmtp_sub()`
- an IPW estimator: `lmtp_ipw()`

### Required vs. optional

The following table describes `lmtp` parameter requirements across the provided estimators: 

| Parameter        |   TMLE  |   SDR   | Substitution |   IPW   | Required |
|------------------|:-------:|:-------:|:------------:|:-------:|:--------:|
| data             | &check; | &check; |    &check;   | &check; |  &check; |
| trt              | &check; | &check; |    &check;   | &check; |  &check; |
| outcome          | &check; | &check; |    &check;   | &check; |  &check; |
| nodes            | &check; | &check; |    &check;   | &check; |  &check; |
| baseline         | &check; | &check; |    &check;   | &check; |          |
| cens             | &check; | &check; |    &check;   | &check; |          |
| k                | &check; | &check; |    &check;   | &check; |          |
| shift            | &check; | &check; |    &check;   | &check; |  &check; |
| outcome_type     | &check; | &check; |    &check;   |         |          |
| bounds           | &check; | &check; |    &check;   |         |          |
| learners         |         |         |    &check;   | &check; |          |
| learners_outcome | &check; | &check; |              |         |          |
| learners_trt     | &check; | &check; |              |         |          |
| folds            | &check; | &check; |    &check;   | &check; |          |

<br>

While many parameters aren't required, the default options will likely give subpar (or incorrect) results. Special attention should be given to the `k` parameter which is fully described in the [Node lists & Markov processes] section.

### sl3

`lmtp` relies on the `sl3` package to use ensemble machine learning during estimation procedures. To fully take advantage of the estimators supplied by `lmtp`, users must create and then pass to `lmtp` estimators `sl3` learner stacks.  `sl3` learner stacks are passed to `lmtp` estimators either through the `learners` argument for `lmtp_sub()` and `lmtp_ipw()` or the `learners_trt` and `learners_outcome` arguments for `lmtp_tmle()` and `lmtp_sdr()`. A full list of supplied `sl3` learners can be found [here](https://tlverse.org/sl3/reference/index.html). 

The easiest way to create an `sl3` learner stack is using `sl3::make_learner_stack()`. 

```{r}
library(sl3)

# using learner defaults
lrnrs <- make_learner_stack(Lrnr_mean, 
                            Lrnr_glm, 
                            Lrnr_ranger)

# specifying learner parameters
lrnrs <- 
  make_learner_stack(
    Lrnr_mean, 
    Lrnr_glm,
    list(Lrnr_ranger, 
         num.trees = 1000)
  )
```

The outcome type should guide users on selecting the appropriate learners for a stack when specifying `learners` with `lmtp_sub()` or `learners_outcome` with `lmtp_tmle()` and `lmtp_sdr()`. Regardless of whether an exposure/treatment is continuous or binary, the exposure mechanism is estimated through classification, thus users should only use `sl3` learners that can handle a binary outcome when specifying `learners` with `lmtp_ipw()` or `learners_trt` with `lmtp_tmle()` or `lmtp_sdr()`. 

The ensemble meta-learner is always set to `Lrnr_nnls`. If learner stacks aren't provided, `lmtp` estimators default to an ensemble only made of `Lrnr_mean` and `Lrnr_glm`. 

**It is recommended the user reads through the `sl3` [documentation](https://tlverse.org/sl3/index.html) to fully utilize `lmtp`.**

### Node lists & Markov processes

Estimating causal effects in longitudinal settings requires paying special attention to the time-ordering and relationship among covariates. In the `lmtp` framework, there are 5 types of variable nodes: treatment, outcome, baseline, time-varying, and censoring. Treatment and outcome nodes are self-explanatory, baseline nodes are variables that are observed pre-treatment allocation and don't change (i.e., age at treatment assignment), time-varying nodes are variables that (you guessed it...) change over time, censoring nodes indicate if an observation is observed (or censored) at the next time-point.

How these nodes are specified depends on the specific data generating mechanism and should be pre-specified based on a conceptual model (i.e, a DAG). How these nodes are used by `lmtp` estimators is specified by what we're calling a node list. The user doesn't explicitly create the node list themself, instead the user supplies the ingredients and instructions on how to combine. These node list *cooking* instructions are specified through the `k` parameter. 

This is best understood through demonstration. The following DAG specifies 1 baseline node, `W`, 3 treatment nodes, `A1`, `A2`, `A3`, 3 time-varying nodes, `L1`, `L2`, `L3`, and an outcome, `Y`. 

```{r out.width="80%", echo=FALSE}
knitr::include_graphics("dag-1.png")
```

According to the DAG, `Y` is directly affected by all nodes in the model, `k = Inf` would be the correct instructions for creating this node list. 

```{r}
a <- c("A1", "A2", "A3")
nodes <- list(c("W", "L1"), 
              c("L2"), 
              c("L3"))

# we can make sure our specification is correct by checking create_node_list()
create_node_list(a, nodes, baseline = NULL, k = Inf)
```

What if we modify the DAG so that `Y` is only directly affected by `A2`, `L2`, and `W`. We could say this data generating mechanism is now semi-Markov and the correct `k` would be `k = 1`. 

```{r out.width="80%", echo=FALSE}
knitr::include_graphics("dag-2.png")
```

```{r}
a <- c("A1", "A2", "A3")
baseline <- c("W")
nodes <- list(c("L1"), 
              c("L2"), 
              c("L3"))

# again checking or specification
create_node_list(a, nodes, baseline = baseline, k = 1)
```

Censoring nodes are discussed in the [Censored outcomes] section.

## Calculating effects

> The goal of this section is to identify how to estimate different causal effects using `lmtp` estimators.

### Traditional causal effects

$$d_t(a_t, h_t) = a_t - \delta_t$$

### Modified treatment policies

Consider a hypothetical intervention where a treatment/exposure is shifted for a set of user-given regimes. The regime only depends upon the natural value of treatment/exposure and other covariate history.

$$
d_t(a_t, h_t)=\left\{ \begin{array}{l}
    a_t - \delta_t & \text{if $a_t>u_t(h_t) + \delta_t$}\\
    a_t & \text{if $a_t \leq u_t(h_t) + \delta_t$}\\
  \end{array} \right.
$$
This intervention differs from the traditional counterparts in that it only considers a hypothetical intervention where treatment/exposure is shifted, $\delta_t$, for observations where this shift is realistic (what's realistic in this case is defined by $a_t>u_t(h_t) + \delta_t$).

### Shift functions

To estimate the effect of a traditional causal intervention or a modified treatment policy in `lmtp` we need to translate these interventions into a shift function. Shift functions are applied to treatment nodes at each time point. A shift function for a traditional intervention where the exposure decreases by 1 unit for all observations at every time point would look like: 

```{r}
shift <- function(trt) {
  trt - 1
}
```

In contrast, we may interested in the effect of a modified treatment policy where exposure is decreased by 1 unit only among subjects whose exposure wonâ€™t go below 1 if intervened upon:

```{r}
shift <- function(trt) {
  (trt - 1) * (trt - 1 >= 1) + trt * (trt - 1 < 1)
}
```

Shift functions are passed to lmtp estimators through the `shift` argument. Currently, shift functions can only depend on the value of the current treatment node. However, the ability evaluate dynamic treatment regimes will be established in a future version.

```{r, eval = F}
# using the previous shift function with sdr
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
lrnrs <- make_learner_stack(Lrnr_mean, Lrnr_glm)

lmtp_sdr(sim_t4, a, "Y", time_varying, k = 1, shift = shift, 
         learners_outcome = lrnrs, learners_trt = lrnrs, folds = 5)
#> LMTP Estimator: SDR
#>    Trt. Policy: (shift)
#> 
#> Population intervention effect
#>       Estimate: 0.2563
#>     Std. error: 0.0165
#>         95% CI: (0.2241, 0.2886)
```

#### Binary treatment

In the case of a binary treatment/exposure the shift function would simply set treatment/exposure to either 0 or 1 depending on the effect of interest:

```{r, eval = F}
# set exposure to 1 for all observations at all time points
shift <- function(x) 1

# set exposure to 0 for all observations at all time points
shift_0 <- function(x) 0

# a binary trt example
data("iptwExWide", package = "twang")

a <- paste0("tx", 1:3)
nodes <- list(c("gender", "age", "use0"), 
              c("use1"), 
              c("use2"))
lrnrs <- make_learner_stack(Lrnr_mean, Lrnr_glm)

lmtp_tmle(iptwExWide, a, "outcome", nodes, shift = shift, 
          outcome_type = "continuous",
          learners_outcome = lrnrs, learners_trt = lrnrs, folds = 5)
#> LMTP Estimator: TMLE
#>    Trt. Policy: (shift)
#> 
#> Population intervention effect
#>       Estimate: -0.287
#>     Std. error: 0.07
#>         95% CI: (-0.4242, -0.1497)
```

### Censored outcomes

In the (likely) case of missing outcomes, `lmtp` can estimate the effect of a hypothetical treatment regime where all observations remained uncensored at end of follow-up. To do this, the user must supply a character vector of censoring nodes for each treatment time point to `lmtp` estimators through the `cens` argument. Censoring nodes should be defined such that at any time, $t$, if an observation is observed at time $t + 1$ they receive a 1 and a 0 otherwise.

**Note: Censoring nodes must be provided if there are missing outcomes.**

```{r}
head(sim_cens[sim_cens$C1 == 1, ])

head(sim_cens[sim_cens$C1 == 0, ])

head(sim_cens[sim_cens$C2 == 0, ])
```

```{r, eval = F}
# estimating an effect when there is censoring
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")
lrnrs <- make_learner(Lrnr_glm)

lmtp_tmle(sim_cens, a, "Y", nodes, cens = cens, k = 1, 
          shift = function(x) x + 0.5, learners_outcome = lrnrs,
          learners_trt = lrnrs)
#> LMTP Estimator: TMLE
#>    Trt. Policy: (function(x) x + 0.5)
#> 
#> Population intervention effect
#>       Estimate: 0.8869
#>     Std. error: 0.0149
#>         95% CI: (0.8577, 0.916)
```

#### Population mean outcome

In certain situtations, the user may be interested in the population mean outcome under no intervention. In the presence of censoring, this can be estimated by setting `shift = NULL` and indicating censoring nodes. 

```{r, eval = F}
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")
lrnrs <- make_learner(Lrnr_glm)

lmtp_tmle(sim_cens, a, "Y", nodes, cens = cens, k = 1, 
          shift = NULL, learners_outcome = lrnrs,
          learners_trt = lrnrs)
#> LMTP Estimator: TMLE
#>    Trt. Policy: (NULL)
#> 
#> Population intervention effect
#>       Estimate: 0.7978
#>     Std. error: 0.0142
#>         95% CI: (0.7701, 0.8256)
```

### Calculating contrasts

The effects returned by the base `lmtp` functions are population intervention effects, that is the expected mean outcome in the population under the hypothetical intervention. Often, however, we are interested also in the comparison of different interventions to each other or to no intervention at all. This is the role of `lmtp_contrast()`. 

```{r, eval = F}
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")
lrnrs <- make_learner(Lrnr_glm)

fit_shift <- 
  lmtp_tmle(sim_cens, a, "Y", nodes, cens = cens, k = 1, 
            shift = function(x) x + 0.5, learners_outcome = lrnrs,
            learners_trt = lrnrs, folds = 2)

fit_noshift <- 
  lmtp_tmle(sim_cens, a, "Y", nodes, cens = cens, k = 1, 
            shift = NULL, learners_outcome = lrnrs,
            learners_trt = lrnrs, folds = 2)

lmtp_contrast(fit_shift, ref = fit_noshift, type = "additive")
#>   LMTP Contrast: additive
#> Null hypothesis: theta == 0
#> 
#>    theta shift   ref std.error conf.low conf.high p.value
#> 1 0.0995 0.897 0.797   0.00985   0.0802     0.119  <0.001

lmtp_contrast(fit_shift, ref = fit_noshift, type = "rr")
#>   LMTP Contrast: relative risk
#> Null hypothesis: theta == 1
#> 
#>   theta shift   ref std.error conf.low conf.high p.value
#> 1  1.12 0.897 0.797    0.0117      1.1      1.15  <0.001
```

Any number of `lmtp` fits can specified in `lmtp_contrast()` to be compared to either single reference fit or a known scalar. 

```{r, eval = F}
lmtp_contrast(fit_shift, fit_noshift, ref = 0.787)
#> Non-estimated reference value, defaulting type = 'additive'.
#> 
#>   LMTP Contrast: additive
#> Null hypothesis: theta == 0
#> 
#>    theta shift   ref std.error conf.low conf.high p.value
#> 1 0.1099 0.897 0.787    0.0150   0.0805    0.1393  <0.001
#> 2 0.0104 0.797 0.787    0.0142  -0.0174    0.0382   0.464
```

### Bootstrap for sub & IPW

There is no theory to provide standard errors for the substitution or IPW estimator when using data adaptive estimation procedures such as the super learner. Standard errors are thus not provided for the substution and IPW estimators. However, if using a pre-specified parametric model for estimation, (i.e., only including `Lrnr_glm`), inference can be performed using the non-parametric boostrap.

```{r bootstrap, eval = F}
resamples <- list()
for (i in 1:50) {
  resamples[[i]] <- sim_t4[1:100, ][sample(1:100, replace = T), ]
}

a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
d <- function(a) (a - 1) * (a - 1 >= 1) + a * (a - 1 < 1)
lrnrs <- make_learner(Lrnr_glm)

theta <- list()
for (i in 1:50) {
  theta[[i]] <- lmtp_ipw(resamples[[i]], a, "Y", time_varying, 
                         k = 1, shift = d, learners = lrnrs, folds = 2)$theta
}

quantile(unlist(theta), c(0.025, 0.975))
#>       2.5%      97.5% 
#> 0.07720175 0.40026962 
```

## Extra features

> The goal of this section is to identify extra features supported by `lmtp` that can improve user experience. 

### Tidy results

`lmtp` automatically provides a `tidy` method as described in the [`broom`](https://cran.r-project.org/web/packages/broom/index.html) package: 

```{r tidy}
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
d <- function(a) (a - 1) * (a - 1 >= 1) + a * (a - 1 < 1)
lrnrs <- make_learner_stack(Lrnr_glm)

fit <- lmtp_tmle(sim_t4, a, "Y", time_varying, k = 1, shift = d, 
                 learners_outcome = lrnrs, learners_trt = lrnrs, folds = 2)

tidy(fit)
```

### Parallel processing with future

Computation time can quickly increase in situations with lots of time points, complex ensemble learners, and large datasets. In response, `lmtp` provides support for parallel processing using the [`future`](https://cran.r-project.org/web/packages/future/index.html) package. The simplest way to use `lmtp` estimators in parallel is set `plan(multiprocess)`. 

```{r, eval = F}
library(future)

a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
d <- function(a) (a - 1) * (a - 1 >= 1) + a * (a - 1 < 1)
lrnrs <- make_learner_stack(Lrnr_mean, 
                            Lrnr_glm, 
                            Lrnr_ranger)

system.time(
  lmtp_tmle(sim_t4, a, "Y", time_varying, k = 1, shift = d, 
            learners_outcome = lrnrs, learners_trt = lrnrs, folds = 10)
)
#>      user  system  elapsed 
#>  1371.914  34.843  634.613 

plan(multiprocess)

system.time(
  lmtp_tmle(sim_t4, a, "Y", time_varying, k = 1, shift = d, 
            learners_outcome = lrnrs, learners_trt = lrnrs, folds = 10)
)
#>   user  system elapsed 
#>  2.353   0.301 194.322 
```

We recommend consulting the `future` [documentation](https://cran.r-project.org/web/packages/future/future.pdf) for more information.

### Progress bars with progressr

In the presence of long computation time, a lack of user feedback can become very frustrating. To address this, `lmtp` supports the use of progress bars during computation through the [`progressr`](https://cran.r-project.org/web/packages/progressr/index.html) package.

```{r, eval = F}
library(progressr)

with_progress({
  fit <- lmtp_tmle(...)
})
```

We recommend consulting the `progressr` [documentation](https://cran.r-project.org/web/packages/progressr/progressr.pdf) for more information. 

## References
